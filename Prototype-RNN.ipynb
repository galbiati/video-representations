{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import load_data as load\n",
    "from models.model import Model\n",
    "from models.customlayers import *\n",
    "from models.activations import *\n",
    "from training import *\n",
    "\n",
    "import moviepy.editor as mpe\n",
    "from models.AELSTM import *\n",
    "L = tf.layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser('~/Insight/video-representations/frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_epochs = 10\n",
    "batchsize = 4\n",
    "sequence_length = 64\n",
    "\n",
    "model = Model(encoder, lstm_cell, decoder, batchsize, sequence_length)\n",
    "\n",
    "## LSTM-Encoder Training Graph ##\n",
    "\n",
    "training_inputs, training_targets = load.inputs('training', batchsize, training_epochs)\n",
    "\n",
    "encoded, transitioned, decoded = model.build(training_inputs)    # discard decoder here\n",
    "loss = tf.reduce_mean(tf.pow(decoded - training_targets, 2))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "trainable_vars = tf.trainable_variables()\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(tf.gradients(loss, trainable_vars), 1)    # clip those uglies\n",
    "train_step = optimizer.apply_gradients(zip(clipped_gradients, trainable_vars))\n",
    "\n",
    "## LSTM-Encoder Validation Graph ##\n",
    "\n",
    "validation_inputs, validation_targets = load.inputs('validation', batchsize, 1)\n",
    "\n",
    "encoded_validation, transitioned_validation, decoded_validation = model.build(validation_inputs, reuse=True)\n",
    "targeted_validation = model.build_target_encoder(validation_targets, reuse=True)\n",
    "validation_loss = tf.reduce_mean(tf.pow(decoded_validation - validation_targets, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11986.7\n",
      "250 4042.67\n",
      "500 2793.53\n",
      "750 2125.74\n",
      "1000 1633.41\n",
      "1250 1438.24\n",
      "1500 2393.27\n",
      "1750 2072.54\n",
      "2000 2465.47\n",
      "2250 1975.53\n",
      "2500 1391.98\n",
      "2750 1811.99\n",
      "3000 1730.34\n",
      "3250 1738.62\n",
      "3500 1255.21\n",
      "3750 1089.03\n",
      "4000 2254.2\n",
      "4250 1493.13\n",
      "4500 1700.49\n",
      "4750 1995.18\n",
      "5000 1244.57\n",
      "5250 1372.68\n",
      "5500 944.866\n",
      "5750 725.929\n",
      "6000 1100.37\n",
      "6250 1661.29\n",
      "6500 984.103\n",
      "6750 1605.84\n",
      "7000 1685.6\n",
      "7250 1389.21\n",
      "7500 1694.43\n",
      "7750 824.17\n",
      "8000 1522.36\n",
      "8250 1411.57\n",
      "8500 1987.66\n",
      "8750 2097.28\n",
      "9000 2045.35\n",
      "9250 1336.58\n",
      "9500 1111.97\n",
      "9750 1138.72\n",
      "10000 1145.7\n",
      "10250 1913.06\n",
      "10500 1702.19\n",
      "10750 1875.87\n",
      "11000 1383.15\n",
      "11250 1184.87\n",
      "11500 1439.15\n",
      "11750 2180.11\n",
      "12000 1717.48\n",
      "12250 1266.66\n",
      "12500 880.351\n",
      "12750 1006.68\n",
      "13000 1330.68\n",
      "13250 1608.1\n",
      "13500 1505.58\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "init_global = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "with tf.Session() as sesh:\n",
    "    sesh.run([init_global, init_local])\n",
    "    threads = tf.train.start_queue_runners(sess=sesh, coord=coord)\n",
    "    \n",
    "    # initialize lists for tracking\n",
    "    \n",
    "    decoder_losses = []\n",
    "    decoder_validation_losses = []\n",
    "    \n",
    "    predictions = []\n",
    "    encodings = []\n",
    "    transitions = []\n",
    "    validation_predictions = []\n",
    "    validation_transitions = []\n",
    "    validation_encodings = []\n",
    "    recovery = []\n",
    "    validation_recovery = []\n",
    "    \n",
    "    # first, encoder training\n",
    "    try:\n",
    "        step = 0\n",
    "        \n",
    "        while not coord.should_stop():\n",
    "            _, loss_value, enc, trans, pred, input_recover = sesh.run(\n",
    "                [train_step, loss, encoded, transitioned, decoded, training_targets]\n",
    "            )\n",
    "            \n",
    "            decoder_losses.append(loss_value)\n",
    "            \n",
    "            if step % 250 == 0:\n",
    "                print(step, loss_value)\n",
    "                encodings.append(enc)\n",
    "                transitions.append(trans)\n",
    "                predictions.append(pred)\n",
    "                recovery.append(input_recover)\n",
    "                \n",
    "            step += 1\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Encoder trained: {:.2f}'.format(loss_value))\n",
    "        \n",
    "    # second, encoder validation\n",
    "    try:\n",
    "        step = 0\n",
    "        \n",
    "        while not coord.should_stop():\n",
    "            _, loss_value, enc, trans, pred, input_recover = sesh.run(\n",
    "                [validation_loss, encoded_validation, transitioned_validation, \n",
    "                 decoded_validation, validation_targets]\n",
    "            )\n",
    "            decoder_validation_losses.append(loss_value)\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(step, loss_value)\n",
    "                validation_encodings.append(enc)\n",
    "                validation_transitions.append(trans)\n",
    "                validation_predictions.append(pred)\n",
    "                validation_recovery.append(input_recover)\n",
    "                \n",
    "            step += 1\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Encoder validated: {:.2f}'.format(loss_value))\n",
    "        \n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    coord.join(threads)\n",
    "    saver.save(sesh, 'ptypelstm')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "axes.plot(decoder_losses)\n",
    "axes.plot(decoder_validation_losses)\n",
    "plt.setp(axes, ylim=[0, 10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predictions[-1][0, 10, :, :, :]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from render import render_movie\n",
    "\n",
    "frame_array = render_movie(predictions[-1][0], 'test_lstm_pred.mp4', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
